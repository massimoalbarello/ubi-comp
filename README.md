This repo is about two projects that were assigned during the class 'Ubiuitous Computing 2021' at ETH Zurich.

The goal of the first task is to extract as much information as possible from a relatively simple datatrace acquired by wearable sensors. It involves consideration of  environmental information and creative approaches to combine them with the measured data. We were given data acquired by wearable sensors worn by a male subject who undertook a day-trip to the popular tourist destination Jungfraujoch in Switzerland. The trip took place sometimes between 01.12.2020 00:01 and 23.12.2020 23:59. Data was acquired by four wearable devices placed right above the ankle, on the wrist, on the chest and on the forehead. The used devices are all identical and continuously measured air pressure at a constant frequency. We were also provided with data acquired by an accelerometer on the chest. 
Based on this data we were able to answer questions like:
- what percentage of the total recorded time did the subject spend at Jungfraujoch?
- for which locations is it possible and reasonable that the subject passed throug hwhile the sensors were active?

While in the first project, we extracted information from a series of sensors about a person’s physicalstate. In the second one, we used sensor values to learn more about a person’s internal state. Specifically, we were provided with electrocardiograms (ECG), electroencephalograms (EEG),electrodermal activities (EDA) (also known as galvanic skin response (GSR)) and facial landmark trajectories (EMO) of 44 participants as they watched different affective movie clips from the ASCERTAIN dataset. Our goal was to build a system that recognizes a participant’s current emotional state as described by valence and arousal. We trained a random forest (RF) classifier with a set of suitable features, which we extracted from the given data, and the corresponding valence and arousal levels that participants have assigned themselves after watching each clip. 